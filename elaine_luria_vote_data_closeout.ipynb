{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "elaine_luria_vote_data_closeout.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMFUnGqknIj7EFOKkHFq9jG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zapatos24/luria_vote_data_closeout/blob/jeremy-wip/elaine_luria_vote_data_closeout.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "697Qp-BKeS1I"
      },
      "source": [
        "**Elaine Luria Voter Data Closeout**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZZlEZgmhekL",
        "outputId": "81889b7d-d976-4b59-a0ad-732578748275"
      },
      "source": [
        "# !pip install gspread-pandas\n",
        "!pip install --upgrade gspread"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: gspread in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from gspread) (1.17.2)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from gspread) (0.4.2)\n",
            "Requirement already satisfied, skipping upgrade: requests>=2.2.1 in /usr/local/lib/python3.6/dist-packages (from gspread) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.12.0->gspread) (4.1.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.12.0->gspread) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.12.0->gspread) (4.6)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.12.0->gspread) (50.3.2)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.12.0->gspread) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib>=0.4.1->gspread) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->gspread) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->gspread) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->gspread) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->gspread) (2020.11.8)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth>=1.12.0->gspread) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxJAMsn7eJBe"
      },
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import json\n",
        "import time"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkJR14VCh-Ob"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R48SyLgseP24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3834a1fc-7d37-4336-f94b-78899b726efa"
      },
      "source": [
        "#Parse all counties associated with VA 02\n",
        "house_district = '02'\n",
        "counties = []\n",
        "path = \"https://results.elections.virginia.gov/vaelections/2020%20November%20General/Json/Member_House_of_Representatives_({}).json\".format(house_district)\n",
        "\n",
        "r = requests.get(path)\n",
        "\n",
        "county_data = json.loads(r.text)\n",
        "for locality in county_data['Localities']:\n",
        "    counties.append(locality['Locality']['LocalityName'])\n",
        "\n",
        "print(counties)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ACCOMACK COUNTY', 'HAMPTON CITY', 'JAMES CITY COUNTY', 'NEWPORT NEWS CITY', 'NORFOLK CITY', 'NORTHAMPTON COUNTY', 'POQUOSON CITY', 'VIRGINIA BEACH CITY', 'WILLIAMSBURG CITY', 'YORK COUNTY']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZbfD14QjzNh"
      },
      "source": [
        "#iterate through counties in district and pull data for each precinct into list of dictionaries\n",
        "precinct_house_list = []\n",
        "precinct_pres_list = []\n",
        "\n",
        "#names on the ballot for each candidate\n",
        "d_house_name = 'Elaine G. Luria'\n",
        "r_house_name = 'Scott W. Taylor'\n",
        "d_pres_name = 'Joseph R. Biden'\n",
        "r_pres_name = 'Donald J. Trump'\n",
        "\n",
        "#create new list of counties that replace a space with an underscore\n",
        "counties_no_space = [c.replace(' ', '_') for c in counties]\n",
        "\n",
        "site_source = 'https://results.elections.virginia.gov/'\n",
        "\n",
        "#iterate through counties and parse precinct level vote data\n",
        "for county in counties_no_space:\n",
        "    house_county_path = 'vaelections/2020%20November%20General/Json/Locality/{}/Member_House_of_Representatives_({}).json'.format(county, house_district)\n",
        "    pres_county_path = 'vaelections/2020%20November%20General/Json/Locality/{}/President_and_Vice_President.json'.format(county)\n",
        "    \n",
        "    house_path = site_source + house_county_path\n",
        "    pres_path = site_source + pres_county_path\n",
        "\n",
        "    #create dict for house precinct results\n",
        "    r_house = requests.get(house_path)\n",
        "    precinct_house_data = json.loads(r_house.text)\n",
        "\n",
        "    #create dict for pres precinct results\n",
        "    r_pres = requests.get(pres_path)\n",
        "    precinct_pres_data = json.loads(r_pres.text)\n",
        "\n",
        "    #iterate through house data for each precinct\n",
        "    for p in precinct_house_data['Precincts']:\n",
        "        p_dict = {}\n",
        "        p_dict['Precinct'] = p['PrecinctName'][:-5]\n",
        "        p_dict['State Senate District'] = ''\n",
        "        p_dict['House District'] = ''\n",
        "        p_dict['County/Locality'] = county\n",
        "\n",
        "        #for each list of candidates, add data for corresponding house candidate\n",
        "        for i in range(len(p['Candidates'])):\n",
        "            if p['Candidates'][i]['BallotName'] == r_house_name:\n",
        "                p_dict['Taylor Votes'] = p['Candidates'][i]['Votes']\n",
        "                p_dict['Taylor Percentage'] = p['Candidates'][i]['Percentage']\n",
        "            elif p['Candidates'][i]['BallotName'] == d_house_name:\n",
        "                p_dict['Luria Votes'] = p['Candidates'][i]['Votes']\n",
        "                p_dict['Luria Percentage'] = p['Candidates'][i]['Percentage']\n",
        "\n",
        "        #append info for precinct to list of precinct house data\n",
        "        precinct_house_list.append(p_dict)\n",
        "\n",
        "    #iterate through president data for each precinct\n",
        "    for p in precinct_pres_data['Precincts']:\n",
        "        p_dict = {}\n",
        "\n",
        "        #only parse data for those in \n",
        "        if p['PrecinctName'][-4:] == '(02)':\n",
        "            p_dict['Precinct'] = p['PrecinctName'][:-5]\n",
        "            p_dict['County/Locality'] = county\n",
        "\n",
        "        #for each list of candidates, add data for corresponding pres candidate\n",
        "            for i in range(len(p['Candidates'])):\n",
        "                if p['Candidates'][i]['BallotName'] == r_pres_name:\n",
        "                    p_dict['Trump Votes'] = p['Candidates'][i]['Votes']\n",
        "                    p_dict['Trump Percentage'] = p['Candidates'][i]['Percentage']\n",
        "                elif p['Candidates'][i]['BallotName'] == d_pres_name:\n",
        "                    p_dict['Biden Votes'] = p['Candidates'][i]['Votes']\n",
        "                    p_dict['Biden Percentage'] = p['Candidates'][i]['Percentage']\n",
        "\n",
        "            #append info for precinct to list of precinct pres data\n",
        "            precinct_pres_list.append(p_dict)\n",
        "\n",
        "    #short sleep to not overtax government servers\n",
        "    time.sleep(.5)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YTy9wMUjzD7"
      },
      "source": [
        "#Convert lists of dictionaries into pandas dataframes and join on County and Precinct\n",
        "house_df = pd.DataFrame(precinct_house_list)\n",
        "pres_df = pd.DataFrame(precinct_pres_list)\n",
        "\n",
        "main_df = house_df.merge(pres_df, how='left', on=['Precinct', 'County/Locality'])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BqnBdzSfVbr"
      },
      "source": [
        "export_cols = [\"Precinct\",\n",
        "               \"State Senate District\",\t\n",
        "               \"House District\",\n",
        "               \"County/Locality\",\n",
        "               \"Taylor Votes\",\n",
        "               \"Taylor Percentage\",\n",
        "               \"Luria Votes\",\n",
        "               \"Luria Percentage\",\n",
        "               \"Trump Votes\",\n",
        "               \"Trump Percentage\",\n",
        "               \"Biden Votes\",\n",
        "               \"Biden Percentage\"]\n",
        "\n",
        "#reorder df for preferred column order\n",
        "export_df = main_df[export_cols]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwPklo0ybFQc",
        "outputId": "3906121f-daaf-4752-8295-e06d4161231e"
      },
      "source": [
        "#Update df values into Google Sheet\n",
        "sh = gc.open(\"Voter Data Close Out Project 2020\")\n",
        "wks = sh.worksheet(\"VA02 Results\")\n",
        "\n",
        "cell_range = 'A2:L{}'.format(str(len(export_df)+1))\n",
        "\n",
        "wks.update('A2:L1000', export_df.values.tolist())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'spreadsheetId': '1TljHbNTUYeXcPAC4U0OtxrrcUMa_ZpO3qq4wZ39ysgw',\n",
              " 'updatedCells': 2316,\n",
              " 'updatedColumns': 12,\n",
              " 'updatedRange': \"'VA02 Results'!A2:L194\",\n",
              " 'updatedRows': 193}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKe9St9dqrUu"
      },
      "source": [
        "END"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77uLIhQqqttq"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    }
  ]
}